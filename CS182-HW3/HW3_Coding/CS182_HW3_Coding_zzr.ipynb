{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2401ead",
   "metadata": {},
   "source": [
    "# CS182 HW3 Coding [40 points]\n",
    "\n",
    "In this coding homework, you will be required to complete several models for binary classification and try to find the inplicit relationship of them by yourself. \n",
    "\n",
    "**Good luck!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1700370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from scipy import special\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce572b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.loadtxt('data/X_train.txt')\n",
    "X_val = np.loadtxt('data/X_val.txt')\n",
    "X_test = np.loadtxt('data/X_test.txt')\n",
    "y_train = np.loadtxt('data/y_train.txt')\n",
    "y_val = np.loadtxt('data/y_val.txt')\n",
    "y_test = np.loadtxt('data/y_test.txt')\n",
    "\n",
    "w = np.loadtxt('data/w.txt')\n",
    "w0 = np.loadtxt('data/w0.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7697c3",
   "metadata": {},
   "source": [
    "## (a) Simple Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21414ceb",
   "metadata": {},
   "source": [
    "(1) Activation functions and loss functions are important parts of each neural network, and there are multiple ways of calculating them. \n",
    "\n",
    " **[3 points]** In this question, we ask you to implement the **sigmoid function** and **binary cross entroy loss function** serving for the binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a08486cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def BCEloss(y_pred, y):\n",
    "    y_new = y*np.log(y_pred)+(1-y)*np.log(1-y_pred)\n",
    "    sum = np.sum(y_new)\n",
    "    return -sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b74b28f",
   "metadata": {},
   "source": [
    "(2) **[3 points]** In this question, we ask you to implement the **softmax function** and **cross entroy loss function** serving for the multiple classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc0c07bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    sum_exp_x = np.sum(exp_x)\n",
    "    return exp_x/sum_exp_x\n",
    "def cross_entropy_loss(y,y_pre):\n",
    "    y_new = y*np.log(y_pre)\n",
    "    sum = np.sum(y_new)\n",
    "    return -sum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9629407c",
   "metadata": {},
   "source": [
    "(3) **[10 points]** Learning a simple perceptron with **batch GD** (using the given initializations $w^{init}$ and $w^{init}_{0}$) based on the training set ($X_{train}$, $y_{train}$): use the training set and the validation set to obtain a good learning rate (you can set the maximum for iterations to 50 and try different learning rate in [$10^{−4}$,  $10^{−8}$] ); output the learned model and evaluate its performance on the test set with the classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0247e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BGD Implementation\n",
    "def cal_gradient(theta, X, Y):\n",
    "    diff = sigmoid(np.dot(X, theta)) - Y\n",
    "    return (1/(2*X.shape[1])) * np.dot(X.transpose(), diff)\n",
    "def BGD(theta, X, Y, max_iteration, learn_rate):\n",
    "    gradient = cal_gradient(theta, X, Y)\n",
    "    for i in range(max_iteration):\n",
    "        theta -= learn_rate*gradient\n",
    "        gradient = cal_gradient(theta, X, Y)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab48f97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best learning rate is 0.0001\n",
      "best accuracy is 0.97\n",
      "classification accuracy is 0.985\n"
     ]
    }
   ],
   "source": [
    "# Evaluation with Sigmoid function\n",
    "learn_accuracy = []\n",
    "max_iteration = 50\n",
    "learn_rates = [1e-4, 1e-8]\n",
    "for learn_rate in learn_rates:\n",
    "    X0 = np.ones((X_train.shape[1], 1))\n",
    "    X = np.hstack((X0, X_train.transpose()))\n",
    "    \n",
    "    theta = np.hstack((w0, w.transpose())).reshape((X_train.shape[0]+1, 1))\n",
    "    BGD(theta, X, y_train.reshape((y_train.shape[0], 1)), max_iteration, learn_rate)\n",
    "    X0 = np.ones((X_val.shape[1], 1))\n",
    "    X = np.hstack((X0, X_val.transpose()))\n",
    "    y_val_pred = np.dot(X, theta)\n",
    "    y_val_pred = sigmoid(y_val_pred)\n",
    "    for i in range(y_val_pred.shape[0]):\n",
    "        if y_val_pred[i]<0.5:\n",
    "            y_val_pred[i]=0\n",
    "        else:\n",
    "            y_val_pred[i]=1\n",
    "    num = 0\n",
    "    for i in range(y_val_pred.shape[0]):\n",
    "        if y_val_pred[i] == y_val[i]:\n",
    "            num += 1\n",
    "    learn_accuracy.append(num/y_val_pred.shape[0])\n",
    "best_learn_rate = learn_rates[learn_accuracy.index(max(learn_accuracy))]\n",
    "print(\"best learning rate is\", best_learn_rate)\n",
    "print(\"best accuracy is\", max(learn_accuracy))\n",
    "#test\n",
    "X0 = np.ones((X_train.shape[1], 1))\n",
    "X = np.hstack((X0, X_train.transpose()))\n",
    "theta = np.hstack((w0, w.transpose())).reshape((X_train.shape[0]+1, 1))\n",
    "BGD(theta, X, y_train.reshape((y_train.shape[0], 1)), max_iteration, best_learn_rate)\n",
    "X0 = np.ones((X_test.shape[1], 1))\n",
    "X = np.hstack((X0, X_test.transpose()))\n",
    "y_test_pred = np.dot(X, theta)\n",
    "y_test_pred = sigmoid(y_test_pred)\n",
    "for i in range(y_test_pred.shape[0]):\n",
    "    if y_test_pred[i]<0.5:\n",
    "        y_test_pred[i]=0\n",
    "    else:\n",
    "        y_test_pred[i]=1\n",
    "num = 0\n",
    "for i in range(y_test_pred.shape[0]):\n",
    "    if y_test_pred[i] == y_test[i]:\n",
    "        num += 1\n",
    "print(\"classification accuracy is\", num/y_test_pred.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531376fe",
   "metadata": {},
   "source": [
    "(4) **[10 points]** Learning a simple perceptron with **SGD** (using the given initializations $w^{init}$ and $w^{init}_{0}$) based on the training set ($X_{train}$, $y_{train}$): use the training set and the validation set to obtain a good learning rate(you can set the maximum for iterations and try different learning rate); output the learned model and evaluate its performance on the test set with the classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "67afd506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD Implementation\n",
    "def cal_gradient_SGD(theta, X, Y):\n",
    "    diff = sigmoid(np.dot(X, theta)) - Y\n",
    "    return 1/2 * np.dot(X.reshape((X.shape[0], 1)), diff).reshape((X.shape[0], 1))\n",
    "def SGD(theta, X, Y, max_iteration, learn_rate):\n",
    "    k = np.random.randint(0, Y.shape[0])\n",
    "    gradient = cal_gradient_SGD(theta, X[k], Y[k])\n",
    "    for i in range(max_iteration):\n",
    "        theta -= learn_rate*gradient\n",
    "        k = np.random.randint(0, Y.shape[0])\n",
    "        gradient = cal_gradient_SGD(theta, X[k], Y[k])\n",
    "    return theta\n",
    "X0 = np.ones((X_train.shape[1], 1))\n",
    "X = np.hstack((X0, X_train.transpose()))\n",
    "max_iteration = 50\n",
    "learn_rate = 1e-4\n",
    "theta = np.hstack((w0, w.transpose())).reshape((X_train.shape[0]+1, 1))\n",
    "k = np.random.randint(0, y_train.shape[0])\n",
    "gradient = cal_gradient_SGD(theta, X[k], y_train.reshape((y_train.shape[0], 1))[k])\n",
    "for i in range(max_iteration):\n",
    "    theta -= learn_rate*gradient\n",
    "    k = np.random.randint(0, y_train.shape[0])\n",
    "    gradient = cal_gradient_SGD(theta, X[k], y_train.reshape((y_train.shape[0], 1))[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6830a8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best learning rate is 0.0001\n",
      "best accuracy is 0.945\n",
      "[[ 4.99396402e-05]\n",
      " [-6.55097633e-04]\n",
      " [-6.42324333e-04]\n",
      " [-7.70599119e-04]\n",
      " [-5.42016182e-04]\n",
      " [-5.41884620e-04]\n",
      " [-4.48406477e-04]\n",
      " [-4.08862325e-04]\n",
      " [-7.34917993e-04]\n",
      " [-6.62351420e-04]\n",
      " [-5.89468179e-04]\n",
      " [-3.98673031e-04]\n",
      " [-3.52484141e-04]\n",
      " [-2.20449065e-04]\n",
      " [-5.26532954e-04]\n",
      " [-4.72711707e-04]\n",
      " [-5.00333796e-04]\n",
      " [-5.65467094e-04]\n",
      " [-7.03165990e-04]\n",
      " [-3.58539543e-04]\n",
      " [-4.30735116e-04]]\n",
      "classification accuracy is 0.985\n"
     ]
    }
   ],
   "source": [
    "# Evaluation with Sigmoid function\n",
    "learn_accuracy = []\n",
    "max_iteration = 50\n",
    "learn_rates = [1e-4, 1e-8]\n",
    "for learn_rate in learn_rates:\n",
    "    X0 = np.ones((X_train.shape[1], 1))\n",
    "    X = np.hstack((X0, X_train.transpose()))\n",
    "    theta = np.hstack((w0, w.transpose())).reshape((X_train.shape[0]+1, 1))\n",
    "    SGD(theta, X, y_train.reshape((y_train.shape[0], 1)), max_iteration, learn_rate)\n",
    "    X0 = np.ones((X_val.shape[1], 1))\n",
    "    X = np.hstack((X0, X_val.transpose()))\n",
    "    y_val_pred = np.dot(X, theta)\n",
    "    y_val_pred = sigmoid(y_val_pred)\n",
    "    for i in range(y_val_pred.shape[0]):\n",
    "        if y_val_pred[i]<0.5:\n",
    "            y_val_pred[i]=0\n",
    "        else:\n",
    "            y_val_pred[i]=1\n",
    "    num = 0\n",
    "    for i in range(y_val_pred.shape[0]):\n",
    "        if y_val_pred[i] == y_val[i]:\n",
    "            num += 1\n",
    "    learn_accuracy.append(num/y_val_pred.shape[0])\n",
    "best_learn_rate = learn_rates[learn_accuracy.index(max(learn_accuracy))]\n",
    "print(\"best learning rate is\", best_learn_rate)\n",
    "print(\"best accuracy is\", max(learn_accuracy))\n",
    "#test\n",
    "X0 = np.ones((X_train.shape[1], 1))\n",
    "X = np.hstack((X0, X_train.transpose()))\n",
    "theta = np.hstack((w0, w.transpose())).reshape((X_train.shape[0]+1, 1))\n",
    "SGD(theta, X, y_train.reshape((y_train.shape[0], 1)), max_iteration, best_learn_rate)\n",
    "print(theta)\n",
    "X0 = np.ones((X_test.shape[1], 1))\n",
    "X = np.hstack((X0, X_test.transpose()))\n",
    "y_test_pred = np.dot(X, theta)\n",
    "y_test_pred = sigmoid(y_test_pred)\n",
    "for i in range(y_test_pred.shape[0]):\n",
    "    if y_test_pred[i]<0.5:\n",
    "        y_test_pred[i]=0\n",
    "    else:\n",
    "        y_test_pred[i]=1\n",
    "num = 0\n",
    "for i in range(y_test_pred.shape[0]):\n",
    "    if y_test_pred[i] == y_test[i]:\n",
    "        num += 1\n",
    "print(\"classification accuracy is\", num/y_test_pred.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e691ce7",
   "metadata": {},
   "source": [
    "## (b) SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321dd481",
   "metadata": {},
   "source": [
    "(1) **[10 points]** Use the function **‘svm’** in package **‘sklearn’** to do the binary classification. Output the model and evaluate its performance on each dataset with the classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "bc84bb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy of training set is 0.9864285714285714\n",
      "classification accuracy of validation set is 0.98\n",
      "classification accuracy of test set is 0.965\n"
     ]
    }
   ],
   "source": [
    "# SVM Implementation\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train.transpose(), y_train)\n",
    "y_train_pred = clf.predict(X_train.transpose())\n",
    "y_val_pred = clf.predict(X_val.transpose())\n",
    "y_test_pred = clf.predict(X_test.transpose())\n",
    "num_train = 0\n",
    "num_val = 0\n",
    "num_test = 0\n",
    "for i in range(y_train_pred.shape[0]):\n",
    "    if y_train_pred[i] == y_train[i]:\n",
    "        num_train += 1\n",
    "for i in range(y_val_pred.shape[0]):\n",
    "    if y_val_pred[i] == y_val[i]:\n",
    "        num_val += 1\n",
    "for i in range(y_test_pred.shape[0]):\n",
    "    if y_test_pred[i] == y_test[i]:\n",
    "        num_test += 1\n",
    "print(\"classification accuracy of training set is\", num_train/y_train_pred.shape[0])\n",
    "print(\"classification accuracy of validation set is\", num_val/y_val_pred.shape[0])\n",
    "print(\"classification accuracy of test set is\", num_test/y_test_pred.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd914a6",
   "metadata": {},
   "source": [
    "## (c) Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3ae058",
   "metadata": {},
   "source": [
    "(1) **[4 points]** Try to compare  models learned from (a)(3), (a)(4) and (b). Write down your explanation and data support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ebbffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "987bd3a25adc08cad34aebf1bf01df59599de62581a3c7f7b5a49c6d1703a598"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
