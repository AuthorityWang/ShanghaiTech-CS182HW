{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2401ead",
   "metadata": {},
   "source": [
    "# CS182 HW3 Coding [40 points]\n",
    "\n",
    "In this coding homework, you will be required to complete several models for binary classification and try to find the inplicit relationship of them by yourself. \n",
    "\n",
    "**Good luck!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1700370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from scipy import special\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce572b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.loadtxt('data/X_train.txt')\n",
    "X_val = np.loadtxt('data/X_val.txt')\n",
    "X_test = np.loadtxt('data/X_test.txt')\n",
    "y_train = np.loadtxt('data/y_train.txt')\n",
    "y_val = np.loadtxt('data/y_val.txt')\n",
    "y_test = np.loadtxt('data/y_test.txt')\n",
    "\n",
    "w = np.loadtxt('data/w.txt')\n",
    "w0 = np.loadtxt('data/w0.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7697c3",
   "metadata": {},
   "source": [
    "## (a) Simple Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21414ceb",
   "metadata": {},
   "source": [
    "(1) Activation functions and loss functions are important parts of each neural network, and there are multiple ways of calculating them. \n",
    "\n",
    " **[3 points]** In this question, we ask you to implement the **sigmoid function** and **binary cross entroy loss function** serving for the binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a08486cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def BCEloss(y_pred, y):\n",
    "    return -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b74b28f",
   "metadata": {},
   "source": [
    "(2) **[3 points]** In this question, we ask you to implement the **softmax function** and **cross entroy loss function** serving for the multiple classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc0c07bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "def cross_entropy_loss(y, y_pre):\n",
    "    return -np.sum(y*np.log(y_pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9629407c",
   "metadata": {},
   "source": [
    "(3) **[10 points]** Learning a simple perceptron with **batch GD** (using the given initializations $w^{init}$ and $w^{init}_{0}$) based on the training set ($X_{train}$, $y_{train}$): use the training set and the validation set to obtain a good learning rate (you can set the maximum for iterations to 50 and try different learning rate in [$10^{−4}$,  $10^{−8}$] ); output the learned model and evaluate its performance on the test set with the classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0247e38",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (7000,) (7000,20) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m     y_pred \u001b[39m=\u001b[39m perceptron(x, w, w0)\n\u001b[0;32m     23\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mround(y_pred)\n\u001b[1;32m---> 25\u001b[0m perceptron_train(np\u001b[39m.\u001b[39;49mtranspose(X_train), y_train, w, w0, \u001b[39m1e-4\u001b[39;49m, \u001b[39m50\u001b[39;49m)\n\u001b[0;32m     26\u001b[0m y_pred \u001b[39m=\u001b[39m perceptron_predict(X_test, w, w0)\n\u001b[0;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m'\u001b[39m, np\u001b[39m.\u001b[39mmean(y_pred \u001b[39m==\u001b[39m y_test))\n",
      "Cell \u001b[1;32mIn[14], line 19\u001b[0m, in \u001b[0;36mperceptron_train\u001b[1;34m(x, y, w, w0, lr, max_iter)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mperceptron_train\u001b[39m(x, y, w, w0, lr, max_iter):\n\u001b[0;32m     18\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iter):\n\u001b[1;32m---> 19\u001b[0m         w, w0 \u001b[39m=\u001b[39m perceptron_update(x, y, w, w0, lr)\n\u001b[0;32m     20\u001b[0m     \u001b[39mreturn\u001b[39;00m w, w0\n",
      "Cell \u001b[1;32mIn[14], line 13\u001b[0m, in \u001b[0;36mperceptron_update\u001b[1;34m(x, y, w, w0, lr)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mperceptron_update\u001b[39m(x, y, w, w0, lr):\n\u001b[1;32m---> 13\u001b[0m     dw, dw0 \u001b[39m=\u001b[39m perceptron_gradient(x, y, w, w0)\n\u001b[0;32m     14\u001b[0m     w \u001b[39m=\u001b[39m w \u001b[39m-\u001b[39m lr \u001b[39m*\u001b[39m dw\n\u001b[0;32m     15\u001b[0m     w0 \u001b[39m=\u001b[39m w0 \u001b[39m-\u001b[39m lr \u001b[39m*\u001b[39m dw0\n",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m, in \u001b[0;36mperceptron_gradient\u001b[1;34m(x, y, w, w0)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mperceptron_gradient\u001b[39m(x, y, w, w0):\n\u001b[0;32m      8\u001b[0m     y_pred \u001b[39m=\u001b[39m perceptron(x, w, w0)\n\u001b[1;32m----> 9\u001b[0m     dw \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean((y_pred \u001b[39m-\u001b[39;49m y) \u001b[39m*\u001b[39;49m x, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     10\u001b[0m     dw0 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(y_pred \u001b[39m-\u001b[39m y)\n\u001b[0;32m     11\u001b[0m     \u001b[39mreturn\u001b[39;00m dw, dw0\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (7000,) (7000,20) "
     ]
    }
   ],
   "source": [
    "# BGD Implementation\n",
    "# Learning a simple perceptron with **batch GD** (using the given initializations $w^{init}$ and $w^{init}_{0}$) based on the training set ($X_{train}$, $y_{train}$): use the training set and the validation set to obtain a good learning rate (you can set the maximum for iterations to 50 and try different learning rate in [$10^{−4}$,  $10^{−8}$] ); output the learned model and evaluate its performance on the test set with the classification accuracy.\n",
    "def perceptron(x, w, w0):\n",
    "    return sigmoid(np.dot(x, w) + w0)\n",
    "def perceptron_loss(x, y, w, w0):\n",
    "    return BCEloss(perceptron(x, w, w0), y)\n",
    "def perceptron_gradient(x, y, w, w0):\n",
    "    y_pred = perceptron(x, w, w0)\n",
    "    dw = np.mean((y_pred - y) * x, axis=0)\n",
    "    dw0 = np.mean(y_pred - y)\n",
    "    return dw, dw0\n",
    "def perceptron_update(x, y, w, w0, lr):\n",
    "    dw, dw0 = perceptron_gradient(x, y, w, w0)\n",
    "    w = w - lr * dw\n",
    "    w0 = w0 - lr * dw0\n",
    "    return w, w0\n",
    "def perceptron_train(x, y, w, w0, lr, max_iter):\n",
    "    for i in range(max_iter):\n",
    "        w, w0 = perceptron_update(x, y, w, w0, lr)\n",
    "    return w, w0\n",
    "def perceptron_predict(x, w, w0):\n",
    "    y_pred = perceptron(x, w, w0)\n",
    "    return np.round(y_pred)\n",
    "\n",
    "perceptron_train(np.transpose(X_train), y_train, w, w0, 1e-4, 50)\n",
    "y_pred = perceptron_predict(X_test, w, w0)\n",
    "print('Accuracy: ', np.mean(y_pred == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab48f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation with Sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531376fe",
   "metadata": {},
   "source": [
    "(4) **[10 points]** Learning a simple perceptron with **SGD** (using the given initializations $w^{init}$ and $w^{init}_{0}$) based on the training set ($X_{train}$, $y_{train}$): use the training set and the validation set to obtain a good learning rate(you can set the maximum for iterations and try different learning rate); output the learned model and evaluate its performance on the test set with the classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67afd506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6830a8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation with Sigmoid function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e691ce7",
   "metadata": {},
   "source": [
    "## (b) SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321dd481",
   "metadata": {},
   "source": [
    "(1) **[10 points]** Use the function **‘svm’** in package **‘sklearn’** to do the binary classification. Output the model and evaluate its performance on each dataset with the classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc84bb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd914a6",
   "metadata": {},
   "source": [
    "## (c) Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3ae058",
   "metadata": {},
   "source": [
    "(1) **[4 points]** Try to compare  models learned from (a)(3), (a)(4) and (b). Write down your explanation and data support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ebbffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "afce4ba17b5757b0751665fe068189bb8136ee183cc24f13fdedfef264cea2cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
